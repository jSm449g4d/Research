Q.なんで超解像?
去年の研究テーマは「文章要約のフレームワークを提唱する」だったんだけど、「文章要約の評価方法」をろくに考えずに進めた結果、行き詰まってテーマを変える必要に迫られた。
次のテーマは「背景」「課題」「評価」をしっかり固めてから研究に取り組む必要がある。
そんな時に時に教授から
「今ではビッグデータ前提で性能だけ求める研究多いけど、限られたデータから情報処理しなければいけないケースってあるよね。"エビデンス的に"」
って助言を頂いた。
実は元々は生成系AI作りたかった関係で超解像(SR)や画像補完(ImageInpainting)の論文も読み漁ってた。その時を反芻したところ、最近GAN使う事前提で、つまりVGG19とか流用する研究ばっかりだなって思った。
去年同期も、今の私と同じような事やってて「VDSRうまくいかねぇ」って悩んでたので、「限られたデータで超解像とかできるモデルがあれば有用性あるんじゃない？」と思ったので話を進めた。
背景: 限られたデータだけで処理しないといけない(ビッグデータ使えない)盤面あるよね
課題: 「出来るだけ少ないデータ数」で「データを高品質」にする
評価: PSNR,SSIMでバッチリ数値化
手法: SRCNNを軸に現代技術で高性能にしていく
という研究指針を立てて開始した。

最初の壁
正直、最初はSRCNNをベースにして改良していけばよいと思ってた...が現実は甘くなかった。
ベースラインのSRCNNがキュービック法と呼ばれる、「単純に画像を引き延ばす」に毛が生えた手法に勝てなかった。
元の論文とかだと、今みたいな「データ数制限」とかないのと、私の実装が悪かった可能性もある...
というわけで片っ端から思いついたり見かけた機械学習モデルを試すことにした。
ネタばれになるが現在(2020/09/01)の所、U-NETの簡略版がほぼ唯一キュービック変換に勝つ可能性があるという状態である。
恐らく、低解像度領域と元解像度領域の二つを残差接続させることにより、両者の特性を組み合わせた認識が可能であるのではないかと考えている。
なお、オリジナルのU-NETに近い構成にすると「問題に対して層の数が多すぎる」ためか精度が悪化するだけとなった。

タスクにノイズ除去を加えている理由
実は保険である。U-NETの簡略版が見つかるまでは、キュービック法に勝てないという可能性もあったからだ。
背景的には「データの高品質化」であるので、ノイズ除去でも文脈は成り立つのだ。
加えるなら、「データの高品質化」が背景なのに、「超解像以外やってません」は流石に厳しい。

次の壁
SRCNNの論文によると、24000枚の33×33のサブ画像で、三倍の超解像として学習している。
それでキュービック法に勝っている。
今回は10000枚の128×128のサブ画像で学習で、八倍の超解像で学習している。
それでキュービック法に惨敗している。
つまり何か実装上に問題が存在したと考えるのが自然である。
Tensorflow上のloss関数(MSE)の結果では、普通に学習成功しているっぽいという結果が得られた。
キュービック法のスコアは81-85
SRCNNの超解像のスコアは77-80
U-Net-EZの超解像のスコアは73-76
つまり、loss関数の結果とPSNRやSSIMの結果が比例していないという結論に至る。
2020/9/4現在loss関数の見直しをおこなっている。
結論として、sklearnのMSEがおかしい説に落ち着いた。評価方法をnumpyで実装したところ、Tensorflowと大体同じ結果になったからだ。
詳しくは異臭#4に書いてある。スコア基準が変化したことで、静略図が大きく変化して、SRCNNがキュービック法に勝っていること、VDSRが有用性のありそうなこと、U-NETが超強いことが分かった。
U-Netは超解像で強いって考えてる奴が私以外にいる事見つけて爆笑した→https://arxiv.org/pdf/1911.09428.pdf
「俺と似たような事考えている奴が、この広い世界のどこかにはいて、叫んでる」っていうのは、すごく微笑ましいし、うれしいことだ。

第三の壁
今は2020/9/5現在。
この研究最大のミッションは「学習データ数の削減」であり、未知の領域だ。達成可能とは正直思えていない。
「限られたデータ数」という体で、飽くまで「学習データ数を削減した時の、機械学習モデルの挙動観測」となるだろう。
今朝、データ数の調整を行う実装を行った。試しにU-NetやSRCNNで128*128の100枚で学習したところ、見事に過学習した。
これは、SRCNNのpaperの33*33の24000枚と比較して、約0.0627倍の教師データサイズで学習する事になる。
trainデータでのスコアが20台まで低下した一方、testデータでのスコアが100をはるかに超えた(キュービック法のスコアは81-85)。
出力データを見ると、画像の細部まで描かれていた(教師―データの出力とは大幅に違うものだったが)。U-Netはまだ掘り下げがいがある。
「学習データ数の削減」を掲げている以上、U-Netはそのまま使えないので、より少ないデータ数でも学習可能なモデルを開発することにした。
現在開発中の物は、「VDSRのVD箇所を、ガンガン正規化とDropoutで不活化したU-Netの超簡略版で、換装したもの」と表現できる。
開発コンセプトは「徹底的な差分」だ。「想像の余地」があると過剰適応する、なので「あらゆる場合において、確実にこうである」と言い切れる時だけ「元画像」に差分修正を加える。
開発は上々、現在のスコアは69-82、酷い過学習を起こしている物の、キュービック法(81-85)以上のスコアは出している。
2020/9/5があと30分程度で終わる。
U-Net→U-Inceptionに変更になった。スコアが殆ど変わらず、過学習に非常に強い為だ。
U-Inception-Bottleneckは100枚学習に強いと思われるが、やはりスコアがUターンする性質がある。出力画像はそれっぽいのだが...

第四の壁
U-InceptionはInception-Unet-SRCNNに変更になった。10000枚8倍超解像が76→74に向上したためだ。
Inception-UnetはDVSRのDVをUnetにリプレースした構造を持つ。VDSRと比較することが重要である。
しかし肝心のVDSRが息をしていない...VDSRが息をしているかいないかで論文の構成や有用性に雲泥の差が出る。VDSRはどうすれば動くのか...

conda install pydot
conda install pydotplus
apt install graphviz
