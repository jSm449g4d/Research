%%
% このファイルはWI2研究会予稿集用スタイルファイル wi2.sty
% を利用したサンプルファイルです。
%
\documentclass[a4paper,twoside]{jarticle}
   \usepackage{wi2}
   \usepackage[dvipdfmx]{graphicx}
   %必要なファイルはインポートして下さい

%和文タイトル
\jtitle{深層学習による少数学習データでの2次元データの高品質化手法の提案}

%著者名
%例1）全員同じ所属
\authors{
%\author{name}{affi_num}{email_num}
%affi_num, email_numを0にすると†やa,b,cが出ません
	\author{石原 正敏}{1}{1}%
	\author{石川 博}{2}{2}%
}
{
%\affi{affi_num}{affiliation}
	\affi{1}{東京都立大学大学院システムデザイン学部情報科学域}%
}
{
%\email{email_num}{email_address}
	\email{1}{ishihara-masatoshi@ed.tmu.ac.jp}%
	\email{2}{ishikawa-hiroshi@tmu.ac.jp}%
}

%例2）複数の所属
%\authors{
%	%\author{name}{affi_num}{email_num}
%	%affi_num, email_numを0にすると†やa,b,cが出ません
%	\author{谷川 恭平}{1}{0}%
%	\author{土方 嘉徳}{2}{1}%
%	\author{西田 正吾}{2}{2}
%}
%{
%	%\affi{affi_num}{affiliation}
%	\affi{1}{大阪大学大学院基礎工学研究科（研究当時）}%
%	\affi{2}{大阪大学大学院基礎工学研究科}%
%}
%{
%	%\email{email_num}{email_address}
%	\email{1}{hijikata@sys.es.osaka-u.ac.jp}%
%	\email{2}{nishida@sys.es.osaka-u.ac.jp}
%}

%例3）改行が必要
%\authors{
%	%\author{name}{affi_num}{email_num}
%	%affi_num, email_numを0にすると†やa,b,cが出ません
%	\author{田中 太郎}{1}{1}%
%	\author{鈴木 花子}{2}{2}%
%	\author{山田 一郎}{3}{3}%
%	\author{谷川 恭平}{4}{4}\\%
%	\author{土方 嘉徳}{4}{5}%
%	\author{西田 正吾}{4}{5}
%}
%{
%	%\affi{affi_num}{affiliation}
%	\affi{1}{なんとか大学かんとか学部}%
%	\affi{2}{なんとか研究所}%
%	\affi{3}{なんとか社かんとか研究所}\\%
%	\affi{4}{大阪大学大学院基礎工学研究科}%
%}
%{
%	%\email{email_num}{email_address}
%	\email{1}{tanaka@nantoka}%
%	\email{2}{suzuki@nantoka}%
%	\email{3}{yamada@nantoka}%
%	\email{4}{tanikawa@nishilab.sys.es.osaka-u.ac.jp}\\%
%	\email{5}{\{hijikata,\,nishida\}@sys.es.osaka-u.ac.jp}
%}

%西暦(4桁)
\YEAR{2020}
\NO{xx}

%\addtolength{\textheight}{-5cm}

\begin{document}

%maketitleはabstractとkeywordの後に入れてください。

\begin{abstract}
近年，データ数が十分に得られないリアルデータや観測データに対応した機械学習モデルが求められている。
本稿では、少数学習でも過学習が起こりにくい2次元データ高品質化手法を提案する。
\end{abstract}

\begin{keyword}	
深層学習, 超解像処理, ノイズ除去
\end{keyword}

\maketitle

\section{はじめに}
機械学習のアプローチの一つに，罰則と報酬によって神経接続(Neural Net)を効率化させていくものがある.この方法は，汎用的な機械学習を実現する手段として注目されてきた\cite{bib1}.
畳み込みニューラルネットワーク(Convolutional Neural Network；CNN)(以降CNN)と呼ばれる構造の登場は，画像処理に大きな影響を及ぼした\cite{bib2}.
画像全体をスライドするように神経接続を構築するので，被写体が画像内のどこであっても特徴を抽出できるからである.
機械学習の課題の一つに過学習(Overfitting)と呼ばれる，訓練データに対して過剰に適合することで未知のデータに対応不能になる現象がある.
Dropoutと呼ばれるランダムで神経細胞(units)を不活化する手法は，過学習抑制に高い効果を示した\cite{bib3}.
ReLUと呼ばれる活性化関数を使用は，深層学習(Deep Learning)の実現を容易にした\cite{bib4}.深層学習を容易に構築可能になった事で、従来よりも複雑な問題を解決可能となった.

今日における深層学習の応用の一つにデータの高品質化がある.
高品質化のアプローチ一つに，単一画像超解像(Single image super resolution)と呼ばれる解像度の低いデータを高解像化するものがある.
月面DEMの高解像度化\cite{bib5}や深海海底地形図の作成\cite{bib6}，CTやMRI画像の超解像\cite{bib7}が例として挙げられる.
他のアプローチとしては，ノイズ除去がある.
ラマン散乱顕微鏡画像のノイズ除去\cite{bib8}や手書き文字画像のノイズ除去\cite{bib9}が例として挙げられる.

一方で，常に十分な学習用のデータ数が得られるとは限らない.
早期胃がんの判別\cite{bib8}や


データ数が十分に得られないリアルデータや観測データに対応した深層学習モデルが求められている。



\section{関連研究}
\section{提案手法}
\section{評価方法}
\section{結果}
\section{おわりに}

\subsection{用紙と余白}
用紙はA4サイズとし，左右の余白はそれぞれ21mm，上下の余白はそれぞれ25mmとしてください．1ページ目は，右上に，「ARG WI2 No.xx, 年号」(Times-Roman 10ポイント）を書いてください（例：「ARG WI2 No.1, 2012」）．TeXスタイルファイルでは，年号と番号はそれぞれ，\verb+\+YEAR\{xxxx\}と\verb+\+NO\{xx\}で与えます．次ページ以降は偶数ページには上の余白中央に「Webインテリジェンスとインタラクション研究会予稿集」（ゴシック体 7ポイント）と書いてください．奇数ページには，「Proceedings of ARG WI2」（Times-Roman Bold 7ポイント）と書いてください．

\subsection{論文タイトル}
タイトルページには，テキスト領域には本文に先立ち，\\
\noindent (1) 和文論文題目(ゴシック体 17ポイント)\\
\noindent (2) 和文著者氏名(明朝体 14ポイント)\\
\noindent (3) 和文所属(明朝体 11ポイント)\\
\noindent (4) E-mail アドレス(Times-Roman Italic 10ポイント)\\
を記述してください．概要は400字程度（ロング発表），300字程度（ショート発表）とします．キーワードは3〜5個程度とします．
これらはページの左右中央に幅145mmの領域
に収まるように配置します．また，項目の間には適当なスペースを挿入してください．ページの左下に脚注として，「Copyright is held by the author(s).」と「The article has been published without reviewing.」(Times-Roman 7ポイント)をそれぞれ書いてください．

\subsection{本文}
本文はテキスト領域に2段組で記述します．段の間隔は8mmです．1つの段の幅は80mmです．本文は必要に応じて章および節に区切って記述します．章の見出しは章番号および章題目(ゴシッ
ク体11ポイント)を「2 背景と目的」の形式で記述します．節の見出しは章節番号および節題目(ゴシック体10.5ポイント)を「2.1 従来の研究」の形式で記述する．
タイトルに続いて文章段落(明朝体10ポイント・インデント)を開始します．段落頭のインデントは1文字程度とします．句読点は「，」と「．」をそれぞれ用いてください．

\section{わいばーん}
必要に応じて，本文の後に謝辞を記述することができます．謝辞の見出しは章題目と同様のスタイル(ゴシック体11ポイント)で「謝辞」と記述します．ただし，章番号はつけません．文章段落は本文と同じスタイルとします．


\begin{figure}[ht]
\begin{center}
\includegraphics[width=.4\textwidth]{onigiri.png}
\end{center}
\caption{システム構成}
\label{fig:zu}
\end{figure}



\begin{table}[ht]
\caption{精度と時間}
\label{tab:ta}
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
subject & accuracy [mm] & time [ms]\\ \hline
s1      & 32       & 5568  \\ \hline
s2      & 63       & 382  \\ \hline
s3      & 12       & 421  \\ \hline
s4      & 51       & 763  \\ \hline
\end{tabular}
\end{center}
\end{table}

\subsection{参照}
参考文献および図表は本文中で必ず参照されなければなりません．参考文献は参
照番号を用いての形式で参照します．同様に図表はそれぞれ
「図\ref{fig:zu}」「表\ref{tab:ta}」の形式で参照します．


\begin{thebibliography}{99}
%人知マニアのロマン汁
\bibitem{bib1} Samuel Arthur L.: Some studies in machine learning using the game of checkers,  IBM Journal of research and development, Vol.3, No.3, pp. 210-229, 1959.
\bibitem{bib2} LeCun Yann, et al.: Gradient-based learning applied to document recognition,  Proceedings of the IEEE, Vol.86, No.11, pp. 2278-2324, 1998.
\bibitem{bib3} Srivastava Nitish, et al.: Dropout: a simple way to prevent neural networks from overfitting,  The journal of machine learning research, Vol.15, No.1, pp. 1929-1958, 2014.
\bibitem{bib4} LeCun Yann, et al.: Deep learning,  nature, Vol.521, No.7553, pp. 436-444, 2015.

%超解像
\bibitem{bib5} 小野寺康祐, ほか： 機械学習による月面DEMの高解像化, 宇宙航空研究開発機構研究開発報告, Vol.9, No.1,pp. 22-32, 2020.
\bibitem{bib6} 伊藤喜代志: 機械学習による超解像技術を活用した詳細な深海海底地形図の作成, 日本水産工学会誌 , Vol.56, No.1, p47-50, 2019
\bibitem{bib7} WEI, Shuaifang, et al.: Improving resolution of medical images with deep dense convolutional neural network, Concurrency and Computation: Practice and Experience, Vol.32, No.1, e5084., 2020.
%ノイズ除去
\bibitem{bib8} MANIFOLD, Bryce, et al.: Denoising of stimulated Raman scattering microscopy images via deep learning,, Biomedical optics express, vol.10, No.8, 3860-3874, 2019
\bibitem{bib9} 小松里奈:  U-Net による手書き文字画像内のノイズ除去, 人工知能学会全国大会論文集, Vol.32, No.1, p.4M101-4M101, 2018
%少数データでの学習の必要性
\bibitem{bib10} 竹本智子, ほか： CNN による少数教師データからの早期胃がん領域の検出, 精密工学会誌, Vol.85, No.9,pp. 761-764, 2019.


\end{thebibliography}



\end{document}
