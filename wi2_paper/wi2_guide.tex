%%
% このファイルはWI2研究会予稿集用スタイルファイル wi2.sty
% を利用したサンプルファイルです。
%
\documentclass[a4paper,twoside]{jarticle}
   \usepackage{wi2}
   \usepackage[dvipdfmx]{graphicx}
   %必要なファイルはインポートして下さい

%和文タイトル
\jtitle{深層学習による少数学習データでの2次元データの高品質化手法の提案}

%著者名
%例1）全員同じ所属
\authors{
%\author{name}{affi_num}{email_num}
%affi_num, email_numを0にすると†やa,b,cが出ません
	\author{石原 正敏}{1}{1}%
	\author{石川 博}{2}{2}%
}
{
%\affi{affi_num}{affiliation}
	\affi{1}{東京都立大学大学院システムデザイン学部情報科学域}%
}
{
%\email{email_num}{email_address}
	\email{1}{ishihara-masatoshi@ed.tmu.ac.jp}%
	\email{2}{ishikawa-hiroshi@tmu.ac.jp}%
}

%例2）複数の所属
%\authors{
%	%\author{name}{affi_num}{email_num}
%	%affi_num, email_numを0にすると†やa,b,cが出ません
%	\author{谷川 恭平}{1}{0}%
%	\author{土方 嘉徳}{2}{1}%
%	\author{西田 正吾}{2}{2}
%}
%{
%	%\affi{affi_num}{affiliation}
%	\affi{1}{大阪大学大学院基礎工学研究科（研究当時）}%
%	\affi{2}{大阪大学大学院基礎工学研究科}%
%}
%{
%	%\email{email_num}{email_address}
%	\email{1}{hijikata@sys.es.osaka-u.ac.jp}%
%	\email{2}{nishida@sys.es.osaka-u.ac.jp}
%}

%例3）改行が必要
%\authors{
%	%\author{name}{affi_num}{email_num}
%	%affi_num, email_numを0にすると†やa,b,cが出ません
%	\author{田中 太郎}{1}{1}%
%	\author{鈴木 花子}{2}{2}%
%	\author{山田 一郎}{3}{3}%
%	\author{谷川 恭平}{4}{4}\\%
%	\author{土方 嘉徳}{4}{5}%
%	\author{西田 正吾}{4}{5}
%}
%{
%	%\affi{affi_num}{affiliation}
%	\affi{1}{なんとか大学かんとか学部}%
%	\affi{2}{なんとか研究所}%
%	\affi{3}{なんとか社かんとか研究所}\\%
%	\affi{4}{大阪大学大学院基礎工学研究科}%
%}
%{
%	%\email{email_num}{email_address}
%	\email{1}{tanaka@nantoka}%
%	\email{2}{suzuki@nantoka}%
%	\email{3}{yamada@nantoka}%
%	\email{4}{tanikawa@nishilab.sys.es.osaka-u.ac.jp}\\%
%	\email{5}{\{hijikata,\,nishida\}@sys.es.osaka-u.ac.jp}
%}

%西暦(4桁)
\YEAR{2020}
\NO{xx}

%\addtolength{\textheight}{-5cm}

\begin{document}

%maketitleはabstractとkeywordの後に入れてください。

\begin{abstract}
近年，データ数が十分に得られないリアルデータや観測データに対応した深層学習モデルが求められている。
本稿では、少数学習でも過学習が起こりにくい2次元データ高品質化手法を提案する。
\end{abstract}

\begin{keyword}	
深層学習, 超解像処理, ノイズ除去
\end{keyword}

\maketitle

\section{はじめに}
データ数が十分に得られないリアルデータや観測データに対応した深層学習モデルが求められている。



\section{関連研究}
\section{提案手法}
\section{評価方法}
\section{結果}
\section{おわりに}

\subsection{用紙と余白}
用紙はA4サイズとし，左右の余白はそれぞれ21mm，上下の余白はそれぞれ25mmとしてください．1ページ目は，右上に，「ARG WI2 No.xx, 年号」(Times-Roman 10ポイント）を書いてください（例：「ARG WI2 No.1, 2012」）．TeXスタイルファイルでは，年号と番号はそれぞれ，\verb+\+YEAR\{xxxx\}と\verb+\+NO\{xx\}で与えます．次ページ以降は偶数ページには上の余白中央に「Webインテリジェンスとインタラクション研究会予稿集」（ゴシック体 7ポイント）と書いてください．奇数ページには，「Proceedings of ARG WI2」（Times-Roman Bold 7ポイント）と書いてください．

\subsection{論文タイトル}
タイトルページには，テキスト領域には本文に先立ち，\\
\noindent (1) 和文論文題目(ゴシック体 17ポイント)\\
\noindent (2) 和文著者氏名(明朝体 14ポイント)\\
\noindent (3) 和文所属(明朝体 11ポイント)\\
\noindent (4) E-mail アドレス(Times-Roman Italic 10ポイント)\\
を記述してください．概要は400字程度（ロング発表），300字程度（ショート発表）とします．キーワードは3〜5個程度とします．
これらはページの左右中央に幅145mmの領域
に収まるように配置します．また，項目の間には適当なスペースを挿入してください．ページの左下に脚注として，「Copyright is held by the author(s).」と「The article has been published without reviewing.」(Times-Roman 7ポイント)をそれぞれ書いてください．

\subsection{本文}
本文はテキスト領域に2段組で記述します．段の間隔は8mmです．1つの段の幅は80mmです．本文は必要に応じて章および節に区切って記述します．章の見出しは章番号および章題目(ゴシッ
ク体11ポイント)を「2 背景と目的」の形式で記述します．節の見出しは章節番号および節題目(ゴシック体10.5ポイント)を「2.1 従来の研究」の形式で記述する．
タイトルに続いて文章段落(明朝体10ポイント・インデント)を開始します．段落頭のインデントは1文字程度とします．句読点は「，」と「．」をそれぞれ用いてください．

\section{わいばーん}
必要に応じて，本文の後に謝辞を記述することができます．謝辞の見出しは章題目と同様のスタイル(ゴシック体11ポイント)で「謝辞」と記述します．ただし，章番号はつけません．文章段落は本文と同じスタイルとします．


\begin{figure}[ht]
\begin{center}
\includegraphics[width=.4\textwidth]{onigiri.png}
\end{center}
\caption{システム構成}
\label{fig:zu}
\end{figure}



\begin{table}[ht]
\caption{精度と時間}
\label{tab:ta}
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
subject & accuracy [mm] & time [ms]\\ \hline
s1      & 32       & 5568  \\ \hline
s2      & 63       & 382  \\ \hline
s3      & 12       & 421  \\ \hline
s4      & 51       & 763  \\ \hline
\end{tabular}
\end{center}
\end{table}

\subsection{参照}
参考文献および図表は本文中で必ず参照されなければなりません．参考文献は参
照番号を用いての形式で参照します．同様に図表はそれぞれ
「図\ref{fig:zu}」「表\ref{tab:ta}」の形式で参照します．


\begin{thebibliography}{99}
\bibitem{bib1} 小野寺康祐,井上博夏,ほか：機械学習による月面DEMの高解像化，	宇宙航空研究開発機構研究開発報告，pp. 22-32, 2020.
\bibitem{bib2} WEI, Shuaifang, et al. Improving resolution of medical images with deep dense convolutional neural network, Concurrency and Computation: Practice and Experience, 32, 1, e5084., 2020.


\bibitem{bib3}
\bibitem{bib2} Smola, A. B., Tanaka, K., Lyan, J., et al.: Computing semantic similarity using ABC theory, Proc. of IEEE/ACM/WIC WI'11, pp. 1540-1547, 2012.
\bibitem{bib3} Smola, A. B., Tanaka, K., Lyan, J., et al.: Computing semantic similarity using ABC theory, Proc. of IEEE/ACM/WIC International Conference on Web Intelligence, pp. 1540-1547, 2012.
\bibitem{bib4} Smola, A. B., Tanaka, K., Lyan, J., et al.: Computing semantic similarity using ABC theory, Proc. of IEEE/ACM/WIC International Conference on Web Intelligence (WI'12), pp. 1540-1547, 2012.
\bibitem{bib5} Z. Wang: All about ABC theory, MIT Press, 2012.
\bibitem{bib6} Chen, N. and Vapnik, J. P.: Computing semantic similarity using ABC theory, Comm. of the ACM, Vol. 45, No. 6, pp. 240-243, 2012.
\bibitem{bib7} Chen, N. and Vapnik, J. P.: Computing semantic similarity using ABC theory, IEEE Trans. on Systems Man and Cybernetics, Vol. 45, No. 6, pp. 240-243, 2012.
\bibitem{bib8} 倉持俊也，土方嘉徳：ABC理論を用いた意味的類似度の計算，〇〇学会論文誌，Vol. 45, No. 6, pp. 240-243, 2012.
\bibitem{bib9} 倉持俊也，谷川恭平，土方嘉徳ほか：ABC理論を用いた意味的類似度の計算，〇〇学会□□研究会，No. 6, pp. 24-29, 2012.
\bibitem{bib10} 倉持俊也，土方嘉徳：ABC理論を用いた意味的類似度の計算，〇〇学会研究報告，DBS-127(FI-67)，pp. 240-243, 2012.
\bibitem{bib11} 倉持俊也，土方嘉徳：ABC理論を用いた意味的類似度の計算，〇〇学会全国大会，in CDROM, 2012.
\bibitem{bib12} 倉持俊也，土方嘉徳：ABC理論を用いた意味的類似度の計算，WebPB Forum'12，pp. 240-243, 2012.
\bibitem{bib13} 倉持俊也，土方嘉徳：ABC理論を用いた意味的類似度の計算，Webとペタベースに関するシンポジウム（WebPB Forum'12），pp. 240-243, 2012.
\bibitem{bib14} 土方嘉徳：ABC理論：基礎と応用，〇〇大学出版，2012.
\bibitem{bib15} 土方嘉徳：解説：ABC理論，知能と情報，Vol.45, No. 6, pp. 1-10, 2012.
\end{thebibliography}



\end{document}
